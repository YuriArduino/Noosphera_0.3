# ğŸ“œ Glyphar â€” OCR Adaptativo para Documentos PsicanalÃ­ticos

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status: Production](https://img.shields.io/badge/status-production-green.svg)]()

**Glyphar** Ã© um pipeline OCR adaptativo e otimizado para extraÃ§Ã£o de textos de documentos psicanalÃ­ticos, integrado ao agente **Thoth** via LangGraph + FastAPI + LLMStudio.

> **Filosofia de Design:** *"Bom o suficiente para correÃ§Ã£o LLM" > "OCR perfeito"*
> Priorizamos velocidade e robustez sobre ganhos marginais de acurÃ¡cia.

---

## ğŸ¯ VisÃ£o Geral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GLYPHAR OCR PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ğŸ“¥ INPUT â†’ ğŸ“– File I/O â†’ ğŸ” Quality Assessment â†’ ğŸ¯ Strategy   â”‚
â”‚                                                                  â”‚
â”‚  ğŸ¯ Strategy â†’ ğŸ–¼ï¸ Preprocessing â†’ ğŸ§  Layout Detection â†’ ğŸ”¤ OCR  â”‚
â”‚                                                                  â”‚
â”‚  ğŸ”¤ OCR â†’ ğŸ“Š Statistics â†’ ğŸ“¤ OCROutput â†’ ğŸ¤– LLM Correction      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Casos de Uso Principais

| CenÃ¡rio | EstratÃ©gia | Velocidade | AcurÃ¡cia |
|---------|-----------|-----------|----------|
| PDFs digitais (nativos) | `fast_scan` | âš¡âš¡âš¡ 1.5s/pÃ¡g | 85-90% |
| Documentos crÃ­ticos | `high_accuracy` | âš¡âš¡ 2.8s/pÃ¡g | 90-95% |
| Scans degradados | `noisy_documents` | âš¡ 3.5s/pÃ¡g | 82-90% |

---

## âœ¨ Funcionalidades Principais

### ğŸ” AnÃ¡lise de Qualidade Adaptativa
- **QualityAssessor** avalia cada pÃ¡gina em <3ms
- MÃ©tricas: `sharpness` (Laplacian), `contrast` (Michelson), `quality_score`
- ClassificaÃ§Ã£o: EXCELLENT | GOOD | FAIR | POOR
- **60-70% dos documentos modernos** pulam prÃ©-processamento pesado

### ğŸ¯ OtimizaÃ§Ã£o DinÃ¢mica de ConfiguraÃ§Ã£o
```python
# ConfigStrategy.decide() seleciona automaticamente:
engine_config = ConfigStrategy.decide(
    layout_type="single",      # ou "double", "complex"
    quality={
        "is_clean_digital": False,
        "sharpness": 85.0,
        "contrast": 0.25,
    }
)
# Result: EngineConfig(pre_type="adaptive", psm=6, scale=1.3, oem=3)
```

### ğŸ“ DetecÃ§Ã£o de Layout
| Detector | PrecisÃ£o | Tempo | Uso |
|----------|---------|-------|-----|
| **ColumnLayoutDetector** | 98.7% (single), 96.3% (double) | ~2ms | 95% dos documentos |
| **AdvancedLayoutDetector** | 88% (multi/complex) | ~15ms | Fallback especializado |

### ğŸ–¼ï¸ Pipeline de PrÃ©-Processamento (8 EstratÃ©gias)
```yaml
execution_order:
  - "polarity_correction"    # Corrige inversÃ£o (texto branco em fundo escuro)
  - "grayscale"              # Converte para luminÃ¢ncia
  - "shadow_removal"         # Remove sombras (CLAHE + background division)
  - "denoise"                # Reduz ruÃ­do (NLM, bilateral, median)
  - "deskew"                 # Corrige inclinaÃ§Ã£o (Â±15Â°)
  - "smart_crop"             # Remove margens vazias
  - "threshold"              # BinarizaÃ§Ã£o (Otsu ou Adaptive)
```

### ğŸ§  Engine Tesseract Gerenciado
- **3 perfis**: `fast` (LSTM), `standard` (LSTM+legacy), `best` (all)
- **Fallback progressivo**: PSM 6 â†’ PSM 11 â†’ PSM 3 (legacy)
- **Cache LRU**: 1000 entradas, ~30% hit rate em batch
- **DicionÃ¡rios de domÃ­nio**: 14 termos psicanalÃ­ticos (Freud, Lacan, inconsciente...)

### ğŸ“¤ Output ImutÃ¡vel (OCROutput)
```python
output = pipeline.process("book.pdf")

# API response
JSONResponse(output.model_dump())

# LLM correction
llm_input = output.llm_ready_text()
# Structure:
# === OCR RESULTS - 320 PAGES ===
# === PAGE 1 | Confidence: 92.3% ===
# [text]
# === END OF DOCUMENT ===

# Dashboard summary
summary = output.summary()
# {file, file_hash, pages, page_hashes, words, average_confidence,
#  processing_time_s, needs_llm_correction}
```

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

```bash
# Ubuntu/Debian
sudo apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-por tesseract-ocr-eng

# macOS
brew install poppler tesseract

# Windows
# Download: https://github.com/UB-Mannheim/tesseract/wiki
# https://github.com/oschwartz10612/poppler-windows
```

### InstalaÃ§Ã£o do Pacote

```bash
# Clone o repositÃ³rio
git clone https://github.com/noosphera/glyphar.git
cd glyphar

# Instale dependÃªncias
pip install -e .

# Ou com todas as extras
pip install -e ".[dev,test]"
```

### VerificaÃ§Ã£o

```bash
# Verificar instalaÃ§Ã£o
python -c "from glyphar import OCRPipeline; print('âœ… Glyphar instalado')"

# Verificar Tesseract
tesseract --version

# Verificar Poppler
pdfinfo -v
```

---

## ğŸ“– Quick Start

### Uso BÃ¡sico

```python
from glyphar import OCRPipeline, OCRConfig
from glyphar.engines.managed.tesseract_managed import TesseractManagedEngine
from glyphar.layout.column_detector import ColumnLayoutDetector

# ConfiguraÃ§Ã£o
config = OCRConfig(
    dpi=200,
    min_confidence=70.0,
    parallel=True,
    max_workers=4,
)

# Engine
engine = TesseractManagedEngine(
    tessdata_dir="resources/tessdata",
    languages="por+eng",
    model_type="fast",
    config=config,
)

# Pipeline
pipeline = OCRPipeline(
    engine=engine,
    layout_detector=ColumnLayoutDetector(),
    _preprocessing_strategies=[],  # Auto-selecionado pelo ConfigOptimizer
    config=config,
    include_llm_input=True,
)

# Processar documento
result = pipeline.process("documento.pdf", parallel=True, max_workers=8)

# Resultados
print(f"âœ… {result.total_pages} pÃ¡ginas processadas")
print(f"â±ï¸  {result.statistics.total_processing_time_s:.1f}s")
print(f"ğŸ“Š AcurÃ¡cia mÃ©dia: {result.average_confidence:.1f}%")

# CorreÃ§Ã£o LLM (se necessÃ¡rio)
if result.needs_llm_correction:
    llm_input = result.llm_ready_text()
    corrected = llm.correct(llm_input)
```

### Processamento em Lote

```python
from pathlib import Path

pdfs = sorted(Path("documents").glob("*.pdf"))

for pdf_path in pdfs:
    result = pipeline.process(str(pdf_path), parallel=True)

    # Salvar output
    (Path("output") / f"{pdf_path.stem}.json").write_text(
        result.model_dump(mode="json"),
        encoding="utf-8",
    )
    (Path("output") / f"{pdf_path.stem}.txt").write_text(
        result.full_text,
        encoding="utf-8",
    )
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### Estrutura de Arquivos

```
docs/
â”œâ”€â”€ capabilities/
â”‚   â”œâ”€â”€ layout.yaml              # DetecÃ§Ã£o de layout
â”‚   â”œâ”€â”€ preprocessing.yaml       # Pipeline de 8 estratÃ©gias
â”‚   â”œâ”€â”€ analysis.yaml            # QualityAssessor
â”‚   â””â”€â”€ engine_modes.yaml        # Perfis fast/standard/best
â”‚
â”œâ”€â”€ tradeoffs/
â”‚   â”œâ”€â”€ performance.yaml         # Benchmarks e targets
â”‚   â””â”€â”€ memory.yaml              # GestÃ£o de memÃ³ria
â”‚
â””â”€â”€ strategies/
    â”œâ”€â”€ fast_scan.yaml           # Velocidade > acurÃ¡cia
    â”œâ”€â”€ high_accuracy.yaml       # AcurÃ¡cia > velocidade
    â””â”€â”€ noisy_documents.yaml     # Robustez para scans degradados
```

### runtime.yaml (Base)

```yaml
version: "1.0.0"

engine:
  model_type: "standard"
  language: "pt"
  enable_layout_analysis: true
  enable_preprocessing: true

pipeline:
  max_workers: 4
  batch_size: 8
  enable_parallelism: true

analysis:
  confidence_threshold: 85.0
  llm_correction_threshold: 92.0

limits:
  max_pages: 500
  max_file_size_mb: 100
  timeout_seconds: 300
```

### Uso com EstratÃ©gias

```bash
# Fast scan (PDFs digitais)
glyphar process document.pdf \
  --config runtime.yaml \
  --strategy docs/strategies/fast_scan.yaml

# Alta acurÃ¡cia (documentos crÃ­ticos)
glyphar process document.pdf \
  --config runtime.yaml \
  --strategy docs/strategies/high_accuracy.yaml

# Documentos ruidosos (scans degradados)
glyphar process document.pdf \
  --config runtime.yaml \
  --strategy docs/strategies/noisy_documents.yaml
```

---

## ğŸ—ï¸ Arquitetura

### Componentes Principais

| MÃ³dulo | Responsabilidade | Arquivos Chave |
|--------|-----------------|----------------|
| **Core** | OrquestraÃ§Ã£o do pipeline | `pipeline.py`, `runner.py`, `page_processor.py`, `file_processor.py` |
| **Engines** | ExecuÃ§Ã£o OCR | `tesseract_core.py`, `tesseract_managed.py`, `config_builder.py`, `fallback.py` |
| **Optimization** | SeleÃ§Ã£o adaptativa | `config_optimizer.py`, `config_strategy.py`, `image_preprocessor.py` |
| **Preprocessing** | EstratÃ©gias de imagem | 8 estratÃ©gias (polarity â†’ threshold) |
| **Layout** | DetecÃ§Ã£o de estrutura | `column_detector.py`, `advanced_detector.py` |
| **Analysis** | MÃ©tricas de qualidade | `quality_assessor.py` |
| **File I/O** | Leitura de arquivos | `readers.py` (PDF + Image) |
| **Models** | Schemas Pydantic | `output.py`, `page.py`, `column.py`, `config.py`, `stats.py` |

### Fluxo de ExecuÃ§Ã£o

```
1. FileProcessor.process(file_path)
   â†“
2. read_pages() â†’ List[NDArray[uint8]]
   â†“
3. run_parallel() ou run_sequential()
   â†“
4. PageProcessor.process(image, page_number, doc_prefix, doc_date)
   â”‚
   â”œâ”€â†’ QualityAssessor.assess(image) â†’ metrics
   â”œâ”€â†’ LayoutDetector.detect(image) â†’ layout_type, regions
   â”œâ”€â†’ ConfigOptimizer.find_optimal_config(image, layout_type, metrics)
   â”‚   â”œâ”€â†’ ConfigStrategy.decide(layout_type, metrics) â†’ EngineConfig
   â”‚   â”œâ”€â†’ ImagePreprocessor.apply(image, pre_type)
   â”‚   â”œâ”€â†’ ImagePreprocessor.upscale(processed, scale)
   â”‚   â””â”€â†’ engine.recognize(processed, {psm, oem})
   â”‚
   â””â”€â†’ PageResult(id, page_number, columns, confidence, ...)
   â†“
5. OCROutput(file_metadata, pages, full_text, statistics, config, ...)
   â†“
6. output.summary() ou output.llm_ready_text()
```

---

## ğŸ“Š Performance

### Benchmarks (Intel i7, 200 DPI)

| Documento | PÃ¡ginas | EstratÃ©gia | Tempo | AcurÃ¡cia | MemÃ³ria |
|-----------|---------|-----------|-------|----------|---------|
| Livro digital | 500 | `fast_scan` | 2 min | 85-90% | 300MB |
| Artigo acadÃªmico | 10 | `fast_scan` | 15s | 88-94% | 50MB |
| Scan degradado | 50 | `noisy_documents` | 3 min | 75-85% | 150MB |

### ComparaÃ§Ã£o de EstratÃ©gias

| MÃ©trica | `fast_scan` | `high_accuracy` | `noisy_documents` |
|---------|-------------|-----------------|-------------------|
| Velocidade (s/pÃ¡g) | 1.5 | 2.8 | 3.5 |
| AcurÃ¡cia | 85-90% | 90-95% | 82-90% |
| MemÃ³ria (MB/pÃ¡g) | 3 | 5 | 6 |
| PrÃ©-processamento | MÃ­nimo | Completo | Agressivo |
| Use Case | PDFs digitais | CrÃ­ticos/arquivo | Scans degradados |

---

## ğŸ”— IntegraÃ§Ã£o com Agente Thoth

### LangGraph Tool Configuration

```python
# Thoth agent â†’ Glyphar tool
from langgraph.graph import StateGraph
from glyphar import OCRPipeline

class ThothState(TypedDict):
    documents: List[str]
    ocr_results: List[OCROutput]
    corrected_texts: List[str]

def glyphar_tool(state: ThothState) -> ThothState:
    pipeline = OCRPipeline(...)

    for doc_path in state["documents"]:
        result = pipeline.process(doc_path)
        state["ocr_results"].append(result)

        if result.needs_llm_correction:
            corrected = llm.correct(result.llm_ready_text())
            state["corrected_texts"].append(corrected)

    return state

# Build graph
graph = StateGraph(ThothState)
graph.add_node("glyphar", glyphar_tool)
graph.set_entry_point("glyphar")
app = graph.compile()
```

### FastAPI Endpoint

```python
from fastapi import FastAPI, UploadFile
from glyphar import OCRPipeline

app = FastAPI()
pipeline = OCRPipeline(...)

@app.post("/process")
async def process_document(file: UploadFile):
    # Save uploaded file
    temp_path = f"/tmp/{file.filename}"
    with open(temp_path, "wb") as f:
        f.write(await file.read())

    # Process
    result = pipeline.process(temp_path, parallel=True)

    # Return summary
    return result.summary()

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

### Docker Compose

```yaml
version: "3.8"

services:
  glyphar:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./resources/tessdata:/app/resources/tessdata
      - ./output:/app/output
    environment:
      - TESSDATA_PREFIX=/app/resources/tessdata
      - GLYPHAR_CONFIG=/app/container.yaml
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  llmstudio:
    image: llmstudio:latest
    ports:
      - "1234:1234"
```

---

## ğŸ§ª Testes

### Executar Testes

```bash
# Testes unitÃ¡rios
pytest tests/unit/ -v

# Testes de integraÃ§Ã£o
pytest tests/integration/ -v

# Teste completo do pipeline (requer PDFs em Test/Data/)
pytest tests/diagnostics/test_full_pipeline_diagnostic.py -v

# Com coverage
pytest --cov=glyphar --cov-report=html
```

### Output do Teste DiagnÃ³stico

```json
// tests/output_data/full_pipeline/summary.json
{
  "pdf_count": 3,
  "results": [
    {
      "file": "PDF_A_Digital.pdf",
      "file_hash": "337f7ee9c65e39d29abd7610b48ad61465fb873b...",
      "pages": 3,
      "page_hashes": ["eba4f439...", "2838c746...", "a15f9c8a..."],
      "words": 846,
      "avg_confidence": 92.4,
      "processing_time_s": 4.36,
      "needs_llm_correction": false
    }
  ]
}
```

---

## ğŸ“š DocumentaÃ§Ã£o

| Documento | DescriÃ§Ã£o |
|-----------|-----------|
| `docs/capabilities/layout.yaml` | ConfiguraÃ§Ã£o de detecÃ§Ã£o de layout |
| `docs/capabilities/preprocessing.yaml` | Pipeline de 8 estratÃ©gias de prÃ©-processamento |
| `docs/capabilities/analysis.yaml` | QualityAssessor e mÃ©tricas |
| `docs/capabilities/engine_modes.yaml` | Perfis fast/standard/best |
| `docs/tradeoffs/performance.yaml` | Benchmarks e targets de performance |
| `docs/tradeoffs/memory.yaml` | GestÃ£o de memÃ³ria e limites |
| `docs/strategies/*.yaml` | EstratÃ©gias prÃ©-configuradas |

---

## ğŸ¤ Contribuindo

### Setup de Desenvolvimento

```bash
# Fork e clone
git clone https://github.com/your-username/glyphar.git
cd glyphar

# Instale em modo development
pip install -e ".[dev]"

# Pre-commit hooks
pre-commit install

# Rodar testes antes de commit
pytest tests/ -v
```

### PadrÃµes de CÃ³digo

```bash
# FormataÃ§Ã£o
black src/ tests/
isort src/ tests/

# Linting
pylint src/glyphar --rcfile=.pylintrc
mypy src/glyphar

# SeguranÃ§a
bandit -r src/glyphar
```

---

## ğŸ“„ LicenÃ§a

MIT License â€” veja [LICENSE](LICENSE) para detalhes.

---

## ğŸ™ Agradecimentos

- **Tesseract OCR** â€” Engine OCR open-source
- **LangGraph** â€” OrquestraÃ§Ã£o de agentes
- **Pydantic** â€” ValidaÃ§Ã£o e schemas
- **OpenCV** â€” Processamento de imagens
- **Projeto Noosphera** â€” Contexto psicanalÃ­tico

---

## ğŸ“ Suporte

- **Issues**: https://github.com/noosphera/glyphar/issues
- **Discussions**: https://github.com/noosphera/glyphar/discussions
- **Email**: thoth@noosphera.ai

---

<div align="center">

**Glyphar** â€” ExtraÃ§Ã£o de texto adaptativa para anÃ¡lise psicanalÃ­tica

[â¬† Voltar ao topo](#-glyphar---ocr-adaptativo-para-documentos-psicanalÃ­ticos)

</div>
