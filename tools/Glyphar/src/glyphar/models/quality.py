"""
Quantitative image quality metrics for adaptive OCR strategy selection.

Generated by QualityAssessor to guide preprocessing decisions:
    - EXCELLENT → skip heavy preprocessing (grayscale only)
    - POOR → apply full preprocessing stack (shadow removal + denoise)
"""

from pydantic import BaseModel, Field
from .enums import PageQuality


class QualityMetrics(BaseModel):
    """
    Objective metrics for document image quality assessment.

    Used by QualityAssessor to determine optimal preprocessing strategy.
    Values guide speed/accuracy trade-offs in OCR pipeline.

    Metric interpretations:
        - sharpness: Laplacian variance (>150 = crisp text suitable for direct OCR)
        - contrast: Michelson ratio (0.0-1.0, >0.4 = high text/background separation)
        - quality_score: Composite metric (sharpness × contrast) for page ranking
        - quality_category: Human-readable classification (EXCELLENT/GOOD/FAIR/POOR)

    Example:
        >>> metrics = QualityAssessor.assess(image)
        >>> if metrics["quality_category"] == PageQuality.EXCELLENT:
        ...     strategies = [GrayscaleStrategy()]
        ... else:
        ...     strategies = [ShadowRemovalStrategy(), AdaptiveThresholdStrategy()]
    """

    sharpness: float = Field(ge=0.0, description="Laplacian variance score")
    contrast: float = Field(ge=0.0, le=1.0, description="Michelson contrast ratio")
    quality_score: float = Field(
        ge=0.0, le=100.0, description="Composite quality score"
    )
    quality_category: PageQuality = Field(default=PageQuality.UNKNOWN)

    noise_level: float = Field(
        default=0.0, ge=0.0, le=1.0, description="Estimated noise ratio (0.0 = clean)"
    )
    text_density: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="Fraction of image area containing text",
    )

    model_config = {"extra": "ignore"}
