"""
LLM Correction Models.

Models for text correction workflow.
"""

from datetime import datetime
from typing import Optional
from pydantic import BaseModel, Field, computed_field


class CorrectionRequest(BaseModel):
    """
    Request sent to LLM for text correction.

    Formatted according to Glyphar analysis.yaml spec.
    """

    ocr_text: str = Field(..., description="OCR text with page markers")
    confidence: float = Field(..., ge=0.0, le=100.0, description="Average OCR confidence")
    system_prompt: str = Field(..., description="System prompt for correction")
    model: str = Field(..., description="LLM model to use")
    temperature: float = Field(default=0.1, ge=0.0, le=2.0)
    max_tokens: int = Field(default=8000, ge=100)

    model_config = {"frozen": True}

    @computed_field
    @property
    def urgency(self) -> str:
        """Determine correction urgency based on confidence."""
        if self.confidence < 70.0:
            return "CRÃTICA"
        elif self.confidence < 85.0:
            return "MODERADA"
        else:
            return "LEVE"


class CorrectionResponse(BaseModel):
    """
    Response from LLM after correction.

    Contains corrected text and metadata.
    """

    corrected_text: str = Field(..., description="Corrected text")
    model: str = Field(..., description="Model used for correction")
    prompt_tokens: int = Field(..., ge=0, description="Tokens in prompt")
    completion_tokens: int = Field(..., ge=0, description="Tokens in completion")
    total_tokens: int = Field(..., ge=0, description="Total tokens used")
    processing_time_s: float = Field(..., ge=0.0)
    corrected_at: datetime = Field(default_factory=datetime.utcnow)

    model_config = {"frozen": True}

    @computed_field
    @property
    def tokens_per_second(self) -> float:
        """Processing throughput in tokens/second."""
        if self.processing_time_s == 0:
            return 0.0
        return self.total_tokens / self.processing_time_s


class CorrectionRecord(BaseModel):
    """
    Complete record of a correction applied.

    Stored for audit trail and learning.
    """

    doc_hash: str = Field(..., description="Document hash")
    doc_name: str = Field(..., description="Document name")
    original_confidence: float = Field(..., ge=0.0, le=100.0)
    original_text_hash: str = Field(..., description="Hash of original OCR text")
    corrected_text_hash: str = Field(..., description="Hash of corrected text")
    model: str = Field(..., description="LLM model used")
    prompt_tokens: int = Field(..., ge=0)
    completion_tokens: int = Field(..., ge=0)
    processing_time_s: float = Field(..., ge=0.0)
    corrected_at: datetime = Field(default_factory=datetime.utcnow)
    success: bool = Field(..., description="Whether correction was successful")
    error_message: Optional[str] = Field(default=None)

    model_config = {"frozen": True}

    @computed_field
    @property
    def was_fallback(self) -> bool:
        """Check if correction fell back to original text."""
        return self.original_text_hash == self.corrected_text_hash
